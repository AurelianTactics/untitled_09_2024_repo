{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "Prototyping LLM EV tool to answer: is it cheaper to buy an EV or a gas car?\n",
    "\n",
    "Input default is the above, but user can add additional information (I want a used car, I live in California, etc.)\n",
    "This tool starts with answering from the broadest perspective and returns a 5 year cost projection\n",
    "this tool then asks for more information to refine the answer\n",
    "\n",
    "\n",
    "working\n",
    "\n",
    "    DONE think through the more advanced graph\n",
    "        maybe I want something that prepares the output for the user given all the information that has been gathered\n",
    "            but if that agent is interacting with the user then isn't it the assistant in a way?\n",
    "            can you tell the assistant how to output? is assitant getting overloaded\n",
    "        I guess make a big prompt for assistant?\n",
    "            then have a reflection node that can critique and offer suggestions\n",
    "\n",
    "        so something like:\n",
    "            user interacts with assistant\n",
    "            based on user prompt, assistant comes up with a plan\n",
    "            uses tools to get the parts\n",
    "                can be sub assistants\n",
    "            sends info back to assistant\n",
    "                maybe this is a different agent/node\n",
    "                maybe plan gets evaluated to make sure all info is good or complete\n",
    "                assistant drafts response\n",
    "            sends draft response to critic\n",
    "                critic evalutes and offers suggestions\n",
    "                sends back to assistant\n",
    "            assistant sends to user\n",
    "                \n",
    "            different ways of doing some parts of this:    \n",
    "                https://langchain-ai.github.io/langgraph/tutorials/rewoo/rewoo/\n",
    "                    planner\n",
    "                https://langchain-ai.github.io/langgraph/tutorials/reflection/reflection/\n",
    "                    reflection\n",
    "\n",
    "    TEST think through this graph a bit more\n",
    "        main thing I am missing is most is user input back to assistant and want to loop on that\n",
    "            but the examples are kind of sparse on that\n",
    "            want the agent to persist and gather more info with each iteration\n",
    "        maybe assume it works out of the box like that like example 1 https://langchain-ai.github.io/langgraph/tutorials/customer-support/customer-support/#part-1-zero-shot-agent\n",
    "            and assume the memory persists\n",
    "        maybe by keeping the thread the same?\n",
    "\n",
    "\n",
    "    TEST simple tool usage\n",
    "        have laid out all I can think of\n",
    "        can do some simple ones to test out some things\n",
    "        not sure how many of htem are needed and what the agent should be able to handle on its own\n",
    "        could group and abstract the key tools\n",
    "            then drill into them as things get better\n",
    "        could try without the tool and run tests and see which are needed\n",
    "            like this idea\n",
    "            see what is needed first then add in the tools\n",
    "        have a couple tools that are included for improving my skills\n",
    "            do a search based tool for federal rebates / credits to start with\n",
    "            everything else in the prompts for now\n",
    "\n",
    "    DONE which tutorial do I want to base this work off of?\n",
    "        leaning towards this one: https://langchain-ai.github.io/langgraph/tutorials/customer-support/customer-support/#part-4-specialized-workflows\n",
    "            There are some other related oens that might be a bit simpler but the above should cover it\n",
    "        Related and many steps but different formats\n",
    "        https://langchain-ai.github.io/langgraph/tutorials/\n",
    "\n",
    "    TEST write some basic code for minimal\n",
    "\n",
    "    continue to organize the plan and notes\n",
    "\n",
    "    research\n",
    "        langraph\n",
    "        tools\n",
    "        similar ideas\n",
    "        do city and towns have ev or car related taxes, fees, registrations etc\n",
    "\n",
    "to do:\n",
    "\n",
    "    more advanced graph initial idea:\n",
    "        think through the more advanced graph\n",
    "        maybe I want something that prepares the output for the user given all the information that has been gathered\n",
    "            but if that agent is interacting with the user then isn't it the assistant in a way?\n",
    "            can you tell the assistant how to output? is assitant getting overloaded\n",
    "        I guess make a big prompt for assistant?\n",
    "            then have a reflection node that can critique and offer suggestions\n",
    "\n",
    "        so something like:\n",
    "            user interacts with assistant\n",
    "            based on user prompt, assistant comes up with a plan\n",
    "            uses tools to get the parts\n",
    "                can be sub assistants\n",
    "            sends info back to assistant\n",
    "                maybe this is a different agent/node\n",
    "                maybe plan gets evaluated to make sure all info is good or complete\n",
    "                assistant drafts response\n",
    "            sends draft response to critic\n",
    "                critic evalutes and offers suggestions\n",
    "                sends back to assistant\n",
    "            assistant sends to user\n",
    "                \n",
    "            different ways of doing some parts of this:    \n",
    "                https://langchain-ai.github.io/langgraph/tutorials/rewoo/rewoo/\n",
    "                    planner\n",
    "                https://langchain-ai.github.io/langgraph/tutorials/reflection/reflection/\n",
    "                    reflection\n",
    "\n",
    "    after testing how the memory works through multiple interactions on the thread\n",
    "        probably want something that goes over the history and stores key piece of info needed\n",
    "        like the location, new or used, etc\n",
    "\n",
    "    maybe initial version is lease versus buy for new EV\n",
    "\n",
    "    improve my personal usage of LLM based coding tools\n",
    "\n",
    "    graph types\n",
    "        just ask the LLM\n",
    "        LLM with tool usage\n",
    "        LLM with sub agents and tool usage\n",
    "\n",
    "    tool usage\n",
    "        start small\n",
    "        start broad\n",
    "            can drill down into more tools as needed\n",
    "        justify tool addition by showing it works better than the prompt\n",
    "        \n",
    "    langsmith\n",
    "    test cases to judge the various iterations of the graphs\n",
    "\n",
    "\n",
    "    move unfinished ideas to a consolidated place in the repo (from code notes and notes outside of repo)\n",
    "\n",
    "    how to handle important discrete pieces of information\n",
    "        ie location\n",
    "        used or new etc\n",
    "        model of car\n",
    "\n",
    "    simple RAG\n",
    "        for the cost estimates probably?\n",
    "\n",
    "    continue to research langgraph docs and other creations people ahve made\n",
    "    research other similar tools online\n",
    "\n",
    "    reflection before passing to user\n",
    "    user backa dn forther\n",
    "\n",
    "    research best time period\n",
    "        research how others like to lay out this info\n",
    "\n",
    "    miles driven and how long the vehicle will likely last\n",
    "        and years too\n",
    "        might be people trade in more recently\n",
    "\n",
    "    better config tavily search results\n",
    "\n",
    "backlog:\n",
    "    can probably store a lot of the data and answers\n",
    "    non US locations\n",
    "    can specifically ask for\n",
    "        kw/hour cost\n",
    "        per gallon gas price\n",
    "    more advanced reasoning graphs\n",
    "    Cost of capital and more advanced financial analysis\n",
    "\n",
    "    advanced RAG of key information\n",
    "        ie like the IRS website and how often should I updated it\n",
    "\n",
    "\n",
    "resources\n",
    "    https://langchain-ai.github.io/langgraph/\n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from typing import Annotated, Literal, Optional\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "import pgeocode\n",
    "\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "_set_env(\"TAVILY_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"EV Prototype v0.4\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_questions_list = [\n",
    "    'What is the cost of owning a new car?',\n",
    "    #'What is the cost of owning an electric vehicle in California?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_graph(graph):\n",
    "    try:\n",
    "        display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    except Exception:\n",
    "        # This requires some extra dependencies and is optional\n",
    "        pass\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v0.01 Minimal LLM Based\n",
    "* Baseline\n",
    "* What if the LLM is asked straight up to answer the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Tried this prompt to copilot. terrible response:\n",
    "# define the langchain graph\n",
    "# the only node should be the LLM node\n",
    "# base the graph off of this tutorial\n",
    "# https://langchain-ai.github.io/langgraph/tutorials/customer-support/customer-support/\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str\n",
    "    # dialog_state: Annotated[\n",
    "    #     list[\n",
    "    #         Literal[\n",
    "    #             \"assistant\",\n",
    "    #             \"update_flight\",\n",
    "    #             \"book_car_rental\",\n",
    "    #             \"book_hotel\",\n",
    "    #             \"book_excursion\",\n",
    "    #         ]\n",
    "    #     ],\n",
    "    #     update_dialog_stack,\n",
    "    # ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "ev_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an assistant that helps gather information for people deciding to buy or lease an electric vehicle or a gas car.\"\n",
    "            \"Help them compare the costs of buying or leasing an electric vehicle or a gas car.\"\n",
    "            \"The fundamental question you are trying to answer is whether it is cheaper to buy an electric vehicle or a gas car.\"\n",
    "            \"If the user does not provide detailed information, answer the question generally.\"\n",
    "            \"If the user does provide detailed information, use that information to provider a better answer.\"\n",
    "            \"Try to ask the user for more information after you provider your answer.\"\n",
    "            \"Some examples of key pieces of information to ask include:\\n\"\n",
    "            \" - Location\\n\"\n",
    "            \" - Used or new\\n\"\n",
    "            \" - Type of car they are interested in (sedan, luxury, compact-SUV, mid-size truck, etc.) \\n\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ev_assistant_runnable = ev_prompt | llm\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"assistant\", Assistant(ev_assistant_runnable))\n",
    "# builder.set_entry_point(\"assistant\")\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "baseline_agent_graph = builder.compile(\n",
    "    checkpoint=memory,\n",
    ")\n",
    "\n",
    "display_graph(baseline_agent_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "_printed = set()\n",
    "for question in testing_questions_list:\n",
    "    events = baseline_agent_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v0.1 LLM and Tools\n",
    "* can do LLM and graph mostly based on the above\n",
    "* will need tool selection part\n",
    "* need tool nodes\n",
    "* need tool functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Possible tools\n",
    "* cost estimate based tools\n",
    "    * tool: estimate various expenses. overall and breakdown when asked\n",
    "        * By subject and by time period (like year)\n",
    "        * start general tool. can then go into better tools as things get better\n",
    "        * car ownership expenses\n",
    "            * insurance\n",
    "                * liability\n",
    "                * gap\n",
    "            * registration\n",
    "            * gas\n",
    "            * electricity\n",
    "                * home charging\n",
    "                * public charging\n",
    "            * maintenance\n",
    "            * state and local fees & taxes\n",
    "            * federal fees and taxes (not applicable I don't think?)\n",
    "            * depreciation\n",
    "            * resale value\n",
    "            * Lesser fees / later\n",
    "                * licensing\n",
    "                * title fees\n",
    "                * dealer add ons like extended warranty etc\n",
    "        * Acquisition related fees\n",
    "            * dealer fees\n",
    "            * down payment\n",
    "            * first monthly payment\n",
    "            * financing fee\n",
    "            * later\n",
    "                * warranty/add ons\n",
    "            * lease related\n",
    "                * lease money down\n",
    "                * lease monthly\n",
    "                * excess mileage on lease\n",
    "                * wear and tear fees on lease\n",
    "                * end of lease vee\n",
    "                * vehicle return\n",
    "                * acquisition fee\n",
    "                * lease downpayment fee\n",
    "* search based tools\n",
    "    * vehicle prices\n",
    "        * new\n",
    "        * used\n",
    "        * lease deals\n",
    "    * insurance quotes\n",
    "    * latest federal rules for rebates\n",
    "    * latest state rules for rebates\n",
    "    * latest state /local fees\n",
    "    * latests federal fees\n",
    "    * cost of electricity by state / zip\n",
    "    * cost of gas by state / zip\n",
    "    * trade in tool\n",
    "    * location: want city and state\n",
    "        can ask specifically or ask for zip\n",
    "* math based / abstraction tools\n",
    "    * make a grid by time period\n",
    "    * make a grid with subect break out\n",
    "    * basic addition between outputs of various things\n",
    "    * handling the outputs of the LLM\n",
    "* finance tools\n",
    "    * loan calculator\n",
    "    * alternative investment\n",
    "* time windwo to consider\n",
    "    * if not user given and miles per year not given then do an overall estimate up to some number\n",
    "        * have to research this\n",
    "* financing vs. down payment vs. how much to put down\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def get_state_and_city_from_zip_code(zip_code: str):\n",
    "    \"\"\"Get the United States state and city from a five digit zip code\n",
    "    \n",
    "    Returns:\n",
    "        state_name: str: The state name. 'unknown' if the zip code is invalid\n",
    "        place_name: str: The city name. 'unknown' if the zip code is invalid\n",
    "    \"\"\"\n",
    "    unknown_value = 'unknown'\n",
    "\n",
    "    if zip_code is None or type(zip_code) is not str or len(zip_code) != 5:\n",
    "        state_name = unknown_value\n",
    "        place_name = unknown_value\n",
    "\n",
    "    else:\n",
    "        nomi = pgeocode.Nominatim('us')\n",
    "\n",
    "        results_df = nomi.query_postal_code(zip_code)\n",
    "\n",
    "        if results_df.shape[0] > 0:\n",
    "            state_name = results_df.state_name\n",
    "            place_name = results_df.place_name\n",
    "        else:\n",
    "            state_name = unknown_value\n",
    "            place_name = unknown_value\n",
    "\n",
    "    return state_name, place_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "ev_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an assistant that helps gather information for people deciding to buy or lease an electric vehicle or a gas car. \"\n",
    "            \"Help them compare the costs of buying or leasing an electric vehicle or a gas car. \"\n",
    "            \"The fundamental question you are trying to answer is whether it is cheaper to buy an electric vehicle or a gas car. \"\n",
    "            \"You have access to the Internt through the Tavily API search tool. \"\n",
    "            \"When using the search tool, be persistent. Expand your search if the first search returns no results. \"\n",
    "            \"If a search comes up empty, expand your search before giving up. \"\n",
    "            \"If the user does not provide detailed information, answer the question generally. \"\n",
    "            \"If the user does provide detailed information, use that information to provider a better answer. \"\n",
    "            \"Try to ask the user for more information after you provider your answer. \" \n",
    "            \"Some examples of key pieces of information to ask include:\\n\"\n",
    "            \" - Location\\n\"\n",
    "            \" - Used or new\\n\"\n",
    "            \" - Type of car they are interested in (sedan, luxury, compact-SUV, mid-size truck, etc.) \\n\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_tool_list = [\n",
    "    TavilySearchResults(max_results=1),\n",
    "    get_state_and_city_from_zip_code,\n",
    "]\n",
    "\n",
    "ev_assistant_runnable = ev_prompt | llm.bind_tools(test_tool_list)\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"assistant\", Assistant(ev_assistant_runnable))\n",
    "# builder.set_entry_point(\"assistant\")\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "baseline_agent_graph = builder.compile(\n",
    "    checkpoint=memory,\n",
    ")\n",
    "\n",
    "display_graph(baseline_agent_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "_printed = set()\n",
    "for question in testing_questions_list:\n",
    "    events = baseline_agent_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervisor, sub-agents, and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
