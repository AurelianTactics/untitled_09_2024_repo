{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbaseline version that is basically without using a graph\\nsee how much can be pushed to the LLM\\n\\nworking\\nwork through the testing code\\n\\nto do\\nTEST prompt\\nTEST simple graph\\nTEST gradio interface\\n    look over old notes\\nTEST evaluate\\n    better testing questions\\n    https://docs.smith.langchain.com/evaluation\\n        do a simple POC and make sure it logs to langsmith\\n\\n\\n\\n\\nbacklog\\n    other ntoes have more backlog items\\n\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "baseline version that is basically without using a graph\n",
    "see how much can be pushed to the LLM\n",
    "\n",
    "working\n",
    "work through the testing code\n",
    "\n",
    "to do\n",
    "TEST prompt\n",
    "TEST simple graph\n",
    "TEST gradio interface\n",
    "    look over old notes\n",
    "TEST evaluate\n",
    "    better testing questions\n",
    "    https://docs.smith.langchain.com/evaluation\n",
    "        do a simple POC and make sure it logs to langsmith\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "backlog\n",
    "    other ntoes have more backlog items\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\james\\github_repos\\untitled_09_2024_repo\\sep2024\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from langchain_openai import OpenAI, ChatOpenAI\n",
    "\n",
    "#from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import Runnable, RunnableConfig\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from typing import Annotated, Literal, Optional\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph.message import AnyMessage, add_messages\n",
    "\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from typing import Literal\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "import pgeocode\n",
    "\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")\n",
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "# _set_env(\"TAVILY_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"EV Prototype v0.4\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_questions_list = [\n",
    "    'What is the cost of owning a 2024 new Chevy Blazer EV compared to the cost of owning a new 2024 Ford Edge?',\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_graph(graph):\n",
    "    try:\n",
    "        display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "    except Exception:\n",
    "        # This requires some extra dependencies and is optional\n",
    "        pass\n",
    "\n",
    "\n",
    "def _print_event(event: dict, _printed: set, max_length=1500):\n",
    "    current_state = event.get(\"dialog_state\")\n",
    "    if current_state:\n",
    "        print(\"Currently in: \", current_state[-1])\n",
    "    message = event.get(\"messages\")\n",
    "    if message:\n",
    "        if isinstance(message, list):\n",
    "            message = message[-1]\n",
    "        if message.id not in _printed:\n",
    "            msg_repr = message.pretty_repr(html=True)\n",
    "            if len(msg_repr) > max_length:\n",
    "                msg_repr = msg_repr[:max_length] + \" ... (truncated)\"\n",
    "            print(msg_repr)\n",
    "            _printed.add(message.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v 0.01 Minimal LLM based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    user_info: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Assistant:\n",
    "    def __init__(self, runnable: Runnable):\n",
    "        self.runnable = runnable\n",
    "\n",
    "    def __call__(self, state: State, config: RunnableConfig):\n",
    "        while True:\n",
    "            result = self.runnable.invoke(state)\n",
    "\n",
    "            if not result.tool_calls and (\n",
    "                not result.content\n",
    "                or isinstance(result.content, list)\n",
    "                and not result.content[0].get(\"text\")\n",
    "            ):\n",
    "                messages = state[\"messages\"] + [(\"user\", \"Respond with a real output.\")]\n",
    "                state = {**state, \"messages\": messages}\n",
    "            else:\n",
    "                break\n",
    "        return {\"messages\": result}\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\")\n",
    "\n",
    "\n",
    "ev_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an assistant that helps gather information for people who want to estimate the cost of a car over 5 years. \"\n",
    "            \"Find the cost of the following: \\n\"\n",
    "            \"- purchasing the car. \\n\"\n",
    "            \"- any rebates the care may be eligible if it is an electric or hybrid car. \\n\"\n",
    "            \"- registration fees and taxes by year. \\n\"\n",
    "            \"- fuel cost. Electric if electric or hybrid car or fuel cost if gas car. \\n\"\n",
    "            \"- maintenance cost. \\n\"\n",
    "            \"Use general estimates if the user does not provide detailed information. \"\n",
    "            \"If the user provides detailed information such as location, insurance quote, used or new car, than use that information. \\n\"\n",
    "        \n",
    "            \"Answer in the format of: \\n\"\n",
    "            \"- vehicle: initial_cost \\n\"\n",
    "            \"- Add a table in the format of the vehicle and cost after each year. \\n\"\n",
    "            \"- Add a table in the format of the vehicle and the total cost of each major expense. \\n\"\n",
    "\n",
    "            \"If the user asks for information on multiple cars, provide that information in an easily comparible way. \\n\"\n",
    "\n",
    "            \"Example: \\n\"\n",
    "            \"I live in New Hampshire and want to know the cost of owning a 2024 new Chevy Blazer EV versus a 2024 Ford Edge. \\n\"\n",
    "            \"Answer: \\n\"\n",
    "            \"New 2024 Chevy Blazer MSRP: $44,600. $37,100 after federal EV rebate \\n\"\n",
    "            \"Total Cost after 5 years: \\n\"\n",
    "            \"New 2024 Ford Edge MSRP: $38,465 \\n\"\n",
    "            \"Total Cost after 5 years: \\n\"\n",
    "            \"Year   |   Chevy Blazer Total Cost |   Ford Edge Total Cost \\n\"\n",
    "            \"Year 1 | 37,600                    |   39,000\\n\"\n",
    "            \"Year 2 | 38,600                    |   41,000\\n\"\n",
    "            \"Year 3 | 39,600                    |   43,000\\n\"\n",
    "            \"Year 4 | 40,600                    |   45,000\\n\"\n",
    "            \"Year 5 | 41,600                    |   47,000\\n\"\n",
    "            \"Total Cost of Major Expenses: \\n\"\n",
    "            \"Item       |   Chevy Blazer   |   Ford Edge \\n\"\n",
    "            \"Fuel       |   1,000          |   1,200\\n\"\n",
    "            \"Maintenance|   2,000          |   2,500\\n\"\n",
    "            \"Registration|  500            |   600\\n\"\n",
    "            \"Insurance  |   1,000          |   1,200\\n\"\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "ev_assistant_runnable = ev_prompt | llm\n",
    "\n",
    "builder = StateGraph(State)\n",
    "\n",
    "builder.add_node(\"assistant\", Assistant(ev_assistant_runnable))\n",
    "# builder.set_entry_point(\"assistant\")\n",
    "builder.add_edge(START, \"assistant\")\n",
    "builder.add_edge(\"assistant\", END)\n",
    "\n",
    "memory = MemorySaver()\n",
    "baseline_agent_graph = builder.compile(\n",
    "    checkpointer=memory,\n",
    ")\n",
    "\n",
    "display_graph(baseline_agent_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is the cost of owning a 2024 new Chevy Blazer EV compared to the cost of owning a new 2024 Ford Edge?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "To estimate the cost of owning a 2024 new Chevy Blazer EV compared to a new 2024 Ford Edge, we will consider several factors including purchasing cost, potential rebates, registration fees and taxes, fuel cost, and maintenance cost. \n",
      "\n",
      "Let's start by gathering some information:\n",
      "- MSRP of the 2024 Chevy Blazer EV\n",
      "- MSRP of the 2024 Ford Edge\n",
      "- Any potential rebates for the Chevy Blazer EV\n",
      "- Location for estimating registration fees and taxes\n",
      "- Estimated fuel cost per year\n",
      "- Estimated maintenance cost per year\n",
      "\n",
      "Once we have this information, we can proceed with the cost estimation for both vehicles. Feel free to provide any additional details you may have to get a more accurate estimation.\n"
     ]
    }
   ],
   "source": [
    "thread_id = str(uuid.uuid4())\n",
    "\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "\n",
    "        # Checkpoints are accessed by thread_id\n",
    "        \"thread_id\": thread_id,\n",
    "    }\n",
    "}\n",
    "\n",
    "_printed = set()\n",
    "for question in testing_questions_list:\n",
    "    events = baseline_agent_graph.stream(\n",
    "        {\"messages\": (\"user\", question)}, config, stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "        _print_event(event, _printed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradio Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_chat_response(user_input: str):\n",
    "    '''\n",
    "\n",
    "    the invoking function calls the graph\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    chat_response: str\n",
    "        Response from the chat agent\n",
    "    \n",
    "    '''\n",
    "\n",
    "    chat_response = \"Error\"\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "    events = baseline_agent_graph.stream(\n",
    "        {\"messages\": (\"user\", user_input)}, config, #stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "\n",
    "        for key, value in event.items():\n",
    "            chat_response = value\n",
    "\n",
    "    return chat_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the Gradio interface\n",
    "with gr.Blocks() as interface:\n",
    "    gr.Markdown(\"## Compare costs of using cars.\")\n",
    "    prompt_input = gr.Textbox(label=\"Prompt\")\n",
    "\n",
    "    # Button to submit the prompt and get the output\n",
    "    generate_button = gr.Button(\"Generate\")\n",
    "\n",
    "    # Textbox to display the LLM's chat response\n",
    "    chat_response_box = gr.Textbox(label=\"Chat Response\", lines=4)\n",
    "\n",
    "    # Link the components together\n",
    "    generate_button.click(fn=generate_chat_response, inputs=prompt_input, outputs=[chat_response_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Launch the interface\n",
    "interface.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval and Test case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a data set\n",
    "# # https://docs.smith.langchain.com/evaluation/how_to_guides/datasets/manage_datasets_programmatically\n",
    "# from langsmith import Client\n",
    "\n",
    "# example_inputs = [\n",
    "# (\"What is the five year cost of a new 2024 Toyata Prius?\", '''\n",
    "# To provide an accurate five-year cost estimate for a 2024 Toyota Prius, I'll break down the key expenses:\n",
    "\n",
    "# Purchase Price\n",
    "\n",
    "\n",
    "# Base model starts around $27,950-$32,000\n",
    "# Mid-range models: $33,000-$38,000\n",
    "# Higher trim levels can reach $40,000+\n",
    "\n",
    "\n",
    "# Fuel Costs\n",
    "\n",
    "\n",
    "# Estimated annual mileage: 12,000 miles\n",
    "# Prius hybrid gets approximately 56 mpg combined\n",
    "# Average gas price: ~$3.50/gallon\n",
    "# Estimated annual fuel cost: $750-$900\n",
    "# 5-year fuel cost: ~$3,750-$4,500\n",
    "\n",
    "\n",
    "# Maintenance\n",
    "\n",
    "\n",
    "# Toyota recommends service every 5,000-10,000 miles\n",
    "# Estimated annual maintenance: $300-$500\n",
    "# 5-year maintenance cost: ~$1,500-$2,500\n",
    "\n",
    "\n",
    "# Insurance\n",
    "\n",
    "\n",
    "# Average annual insurance: $1,400-$2,000\n",
    "# 5-year insurance cost: $7,000-$10,000\n",
    "\n",
    "\n",
    "# Depreciation\n",
    "\n",
    "\n",
    "# Estimated 40-50 percent depreciation over 5 years\n",
    "# Potential value loss: $12,000-$19,000\n",
    "\n",
    "# Estimated Total 5-Year Cost: $52,200-$65,000\n",
    "# These are rough estimates and can vary based on location, driving habits, and specific model chosen.\n",
    "\n",
    "# '''),\n",
    "# ]\n",
    "\n",
    "# client = Client()\n",
    "# dataset_name = \"Basic vehicle questions asdf\"\n",
    "\n",
    "# # Storing inputs in a dataset lets us\n",
    "# # run chains and LLMs over a shared set of examples.\n",
    "# dataset = client.create_dataset(\n",
    "#   dataset_name=dataset_name, description=\"Questions and answers about vehicle costs.\",\n",
    "# )\n",
    "\n",
    "# # Prepare inputs, outputs, and metadata for bulk creation\n",
    "# inputs = [{\"question\": input_prompt} for input_prompt, _ in example_inputs]\n",
    "# outputs = [{\"answer\": output_answer} for _, output_answer in example_inputs]\n",
    "# metadata = [{\"source\": \"working example\"} for _ in example_inputs]\n",
    "\n",
    "# # client.create_examples(\n",
    "# #   inputs=inputs,\n",
    "# #   outputs=outputs,\n",
    "# #   metadata=metadata,\n",
    "# #   dataset_id=dataset.id,\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import evaluate, Client\n",
    "\n",
    "# client = Client()\n",
    "# dataset = client.clone_public_dataset(\n",
    "#     \"https://smith.langchain.com/public/a63525f9-bdf2-4512-83e3-077dc9417f96/d\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langsmith import evaluate, Client\n",
    "\n",
    "# client = Client()\n",
    "# dataset = client.clone_public_dataset(\n",
    "#     \"https://smith.langchain.com/public/a63525f9-bdf2-4512-83e3-077dc9417f96/d\"\n",
    "# )\n",
    "\n",
    "# # 2. Define an evaluator\n",
    "# def is_error_message(outputs: dict, reference_outputs: dict) -> bool:\n",
    "#     if str(outputs[\"answer\"]).lower() == \"error\":\n",
    "#         return True\n",
    "#     return False\n",
    "#     #return len(outputs[\"answer\"]) < (3 * len(reference_outputs[\"answer\"]))\n",
    "\n",
    "# # # 2. Define an evaluator\n",
    "# # def is_concise(outputs: dict, reference_outputs: dict) -> bool:\n",
    "# #     return len(outputs[\"answer\"]) < (3 * len(reference_outputs[\"answer\"]))\n",
    "\n",
    "# # # 3. Define the interface to your app\n",
    "# # def chatbot(inputs: dict) -> dict:\n",
    "\n",
    "# #     generate_chat_response\n",
    "# #     return {\"answer\": inputs[\"question\"] + \" is a good question. I don't know the answer.\"}\n",
    "\n",
    "# def generate_chatbot(inputs: dict) -> dict:\n",
    "#     '''\n",
    "\n",
    "#     the invoking function calls the graph\n",
    "            \n",
    "#     Parameters\n",
    "#     ----------\n",
    "\n",
    "#     Returns\n",
    "#     -------\n",
    "#     chat_response: str\n",
    "#         Response from the chat agent\n",
    "    \n",
    "#     '''\n",
    "\n",
    "#     chat_response = \"Error\"\n",
    "    \n",
    "#     config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "#     events = baseline_agent_graph.stream(\n",
    "#         {\"messages\": (\"user\", inputs[\"question\"])}, config, #stream_mode=\"values\"\n",
    "#     )\n",
    "#     for event in events:\n",
    "\n",
    "#         for key, value in event.items():\n",
    "#             chat_response = value\n",
    "\n",
    "#     return {\"answer\": chat_response}\n",
    "\n",
    "# # 4. Run an evaluation\n",
    "# evaluate(\n",
    "#     generate_chatbot,\n",
    "#     data=dataset,\n",
    "#     evaluators=[is_error_message],\n",
    "#     experiment_prefix=\"basic prototype eval\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'my first experiment -e7ccb6d5' at:\n",
      "https://smith.langchain.com/o/4d4a1df9-252f-54f7-a27f-550564db7e86/datasets/21480c06-434a-40db-a3dc-388fef467aeb/compare?selectedSessions=a765e970-0473-40e8-a668-3280aa9dcc42\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:00, 15.98it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the largest mammal?</td>\n",
       "      <td>What is the largest mammal? is a good question...</td>\n",
       "      <td>None</td>\n",
       "      <td>The blue whale</td>\n",
       "      <td>False</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>9eebe78d-c8cf-4627-8257-4b3674ca7ec8</td>\n",
       "      <td>e9aafd4b-3270-4d7e-a5d7-5227f45a88cd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do mammals and birds have in common?</td>\n",
       "      <td>What do mammals and birds have in common? is a...</td>\n",
       "      <td>None</td>\n",
       "      <td>They are both warm-blooded</td>\n",
       "      <td>False</td>\n",
       "      <td>0.000964</td>\n",
       "      <td>26d18d54-d22f-4dea-9f67-a5ad705f68f6</td>\n",
       "      <td>5df77df3-f34f-4db8-b10c-dc56c27acad9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults my first experiment -e7ccb6d5>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import evaluate, Client\n",
    "\n",
    "# 1. Create and/or select your dataset\n",
    "client = Client()\n",
    "dataset = client.clone_public_dataset(\n",
    "    \"https://smith.langchain.com/public/a63525f9-bdf2-4512-83e3-077dc9417f96/d\"\n",
    ")\n",
    "\n",
    "# 2. Define an evaluator\n",
    "def is_concise(outputs: dict, reference_outputs: dict) -> bool:\n",
    "    return len(outputs[\"answer\"]) < (3 * len(reference_outputs[\"answer\"]))\n",
    "\n",
    "# 3. Define the interface to your app\n",
    "def chatbot(inputs: dict) -> dict:\n",
    "    return {\"answer\": inputs[\"question\"] + \" is a good question. I don't know the answer.\"}\n",
    "\n",
    "# 4. Run an evaluation\n",
    "evaluate(\n",
    "    chatbot,\n",
    "    data=dataset,\n",
    "    evaluators=[is_concise],\n",
    "    experiment_prefix=\"my first experiment \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'my first experiment -09db0d50' at:\n",
      "https://smith.langchain.com/o/4d4a1df9-252f-54f7-a27f-550564db7e86/datasets/21480c06-434a-40db-a3dc-388fef467aeb/compare?selectedSessions=78b58a99-1027-4699-bd14-99eeb28c0b16\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:02,  1.07s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.answer</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.answer</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the largest mammal?</td>\n",
       "      <td>{'messages': content='The largest mammal is th...</td>\n",
       "      <td>None</td>\n",
       "      <td>The blue whale</td>\n",
       "      <td>True</td>\n",
       "      <td>0.818212</td>\n",
       "      <td>9eebe78d-c8cf-4627-8257-4b3674ca7ec8</td>\n",
       "      <td>bf43ac28-d92d-4ba3-bdef-e729b8ab27b5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do mammals and birds have in common?</td>\n",
       "      <td>{'messages': content='Mammals and birds share ...</td>\n",
       "      <td>None</td>\n",
       "      <td>They are both warm-blooded</td>\n",
       "      <td>True</td>\n",
       "      <td>1.990256</td>\n",
       "      <td>26d18d54-d22f-4dea-9f67-a5ad705f68f6</td>\n",
       "      <td>17be993a-7e59-47ae-b0e1-8897e6d8752d</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults my first experiment -09db0d50>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_chatbot(inputs: dict) -> dict:\n",
    "    '''\n",
    "\n",
    "    the invoking function calls the graph\n",
    "            \n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    chat_response: str\n",
    "        Response from the chat agent\n",
    "    \n",
    "    '''\n",
    "\n",
    "    chat_response = \"Error\"\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "    events = baseline_agent_graph.stream(\n",
    "        {\"messages\": (\"user\", inputs[\"question\"])}, config, #stream_mode=\"values\"\n",
    "    )\n",
    "    for event in events:\n",
    "\n",
    "        for key, value in event.items():\n",
    "            chat_response = value\n",
    "\n",
    "    return {\"answer\": chat_response}\n",
    "\n",
    "# 4. Run an evaluation\n",
    "evaluate(\n",
    "    #chatbot,\n",
    "    generate_chatbot,\n",
    "    data=dataset,\n",
    "    evaluators=[is_concise],\n",
    "    experiment_prefix=\"my first experiment \"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dataset' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[38;5;241m.\u001b[39mquestions[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Dataset' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sep2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
